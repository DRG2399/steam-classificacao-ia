# steam-classificacao-ia
Classifica√ß√£o de jogos da Steam com diferentes algoritmos de ML
#Trabalho de Intelig√™ncia Artificial

#Classifica√ß√£o de Jogos da Steam com Algoritmos de Machine Learning

#1. Introdu√ß√£o

Este projeto tem como objetivo aplicar algoritmos de classifica√ß√£o para prever se um jogo da Steam √© "Bom" ou "Ruim", com base em suas avalia√ß√µes e caracter√≠sticas. A base de dados foi obtida do Kaggle:

üîó [Steam Store Games - Kaggle](https://www.kaggle.com/datasets/nikdavis/steam-store-games)

---

#2. Base de Dados

Foram utilizadas as seguintes vari√°veis:

- `price`: Pre√ßo do jogo  
- `release_year`: Ano de lan√ßamento (extra√≠do da data de lan√ßamento)  
- `developer`: Desenvolvedor  
- `average_playtime`: Tempo m√©dio jogado  
- `positive_ratings`, `negative_ratings`: Usadas para calcular o "score do usu√°rio"  

---

#3. Objetivo

Classificar os jogos em duas categorias:

- **Bom**: quando mais de 80% das avalia√ß√µes dos usu√°rios s√£o positivas  
- **Ruim**: caso contr√°rio

---

#4. Algoritmos Utilizados

1. Decision Tree  
2. Random Forest  
3. SVM (Support Vector Machine)  
4. Naive Bayes Gaussiano  

---

#5. Metodologia

- Pr√©-processamento dos dados: limpeza, convers√£o de datas, codifica√ß√£o da vari√°vel `developer`, cria√ß√£o da vari√°vel-alvo  
- Divis√£o em treino/teste (80% / 20%)  
- Avalia√ß√£o com as m√©tricas: **Acur√°cia**, **Precis√£o**, **Recall**, **F1-score**, **Matriz de Confus√£o**  

---

#6. Resultados

#Tabela de Compara√ß√£o

| Algoritmo      | Acur√°cia | Precis√£o (Bom) | Recall (Bom) | F1-Score (Bom) |
|----------------|----------|----------------|--------------|----------------|
| Decision Tree  | 0.5907   | 0.5294         | 0.4834       | 0.5053         |
| Random Forest  | 0.6261   | 0.5796         | 0.4936       | 0.5331         |
| SVM            | 0.6040   | 0.6364         | 0.1969       | 0.3008         |
| Naive Bayes    | 0.5520   | 0.4774         | 0.3785       | 0.4223         |

#Gr√°fico de Acur√°cias

O gr√°fico de compara√ß√£o de acur√°cias por algoritmo est√° dispon√≠vel no google colab e no pdf.

---

#7. Discuss√£o

O algoritmo com melhor desempenho geral foi o **Random Forest**, com uma acur√°cia de 62,61% e o melhor equil√≠brio entre precis√£o, recall e F1-score para a classe ‚ÄúBom‚Äù.

O pior desempenho foi do **Naive Bayes**, com uma acur√°cia de apenas 55,20%, provavelmente por suas fortes suposi√ß√µes sobre distribui√ß√£o e independ√™ncia das vari√°veis ‚Äî o que n√£o reflete bem os dados reais.

Embora o **SVM** tenha tido a maior precis√£o (63,64%) na detec√ß√£o de jogos bons, seu **recall foi muito baixo** (19,69%), indicando que ele deixou de identificar muitos jogos bons.

A **√Årvore de Decis√£o** teve desempenho intermedi√°rio, sendo √∫til pela sua simplicidade e interpretabilidade.

---

#8. Conclus√£o

Todos os modelos apresentaram desempenho razo√°vel, com destaque para o Random Forest.

O projeto mostrou a import√¢ncia do pr√©-processamento e da escolha do modelo. Para trabalhos futuros, seria interessante explorar mais vari√°veis (como g√™neros e tags) e aplicar tuning de hiperpar√¢metros para melhorar os resultados.

---

#Execu√ß√£o

- O c√≥digo foi desenvolvido e testado no Google Colab.  
- Para executar, basta abrir o notebook no Colab e fazer upload do arquivo `steam.csv`.
